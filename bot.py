import os
import requests
import time
from datetime import datetime
import re
import json
from bs4 import BeautifulSoup
import feedparser

TELEGRAM_TOKEN = "7908433957:AAEyetZTWACBNn6t-wHPQwB89p1PtkQEvfg"
CHANNEL_ID = "@fiveleaguesua"

# –î–∂–µ—Ä–µ–ª–∞ –Ω–æ–≤–∏–Ω
NEWS_SOURCES = {
    'google_news': 'https://news.google.com/rss/search?q=football+premier+league+transfer&hl=en&gl=GB&ceid=GB:en',
    'sky_sports': 'https://www.skysports.com/football/news',
    'bbc_sport': 'https://www.bbc.com/sport/football',
}

LEAGUES = {
    'premier league': 'üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø –ê–ü–õ',
    'la liga': 'üá™üá∏ –õ–∞ –õ—ñ–≥–∞', 
    'serie a': 'üáÆüáπ –°–µ—Ä—ñ—è –ê',
    'bundesliga': 'üá©üá™ –ë—É–Ω–¥–µ—Å–ª—ñ–≥–∞',
    'ligue 1': 'üá´üá∑ –õ—ñ–≥–∞ 1',
    'champions league': 'üèÜ –õ—ñ–≥–∞ –ß–µ–º–ø—ñ–æ–Ω—ñ–≤',
    'europa league': 'ü•à –õ—ñ–≥–∞ –Ñ–≤—Ä–æ–ø–∏'
}

CLUBS = {
    'manchester united': 'üî¥ –ú–∞–Ω—á–µ—Å—Ç–µ—Ä –Æ–Ω–∞–π—Ç–µ–¥',
    'manchester city': 'üîµ –ú–∞–Ω—á–µ—Å—Ç–µ—Ä –°—ñ—Ç—ñ',
    'liverpool': 'üî¥ –õ—ñ–≤–µ—Ä–ø—É–ª—å',
    'chelsea': 'üîµ –ß–µ–ª—Å—ñ',
    'arsenal': 'üî¥ –ê—Ä—Å–µ–Ω–∞–ª',
    'tottenham': '‚ö™ –¢–æ—Ç—Ç–µ–Ω–≥–µ–º',
    'real madrid': '‚ö™ –†–µ–∞–ª –ú–∞–¥—Ä–∏–¥',
    'barcelona': 'üîµ –ë–∞—Ä—Å–µ–ª–æ–Ω–∞',
    'juventus': '‚ö´ –Æ–≤–µ–Ω—Ç—É—Å',
    'milan': 'üî¥ –ú—ñ–ª–∞–Ω',
    'bayern': 'üî¥ –ë–∞–≤–∞—Ä—ñ—è',
    'psg': 'üîµ –ü–°–ñ'
}

IMPORTANT_KEYWORDS = [
    "transfer", "signing", "deal", "million", "contract",
    "injury", "ruled out", "return", "fitness",
    "sacked", "fired", "appointed", "manager", "coach",
    "champions league", "europa league", "final",
    "record", "goal", "assist", "performance",
    "rumour", "target", "bid", "offer"
]

processed_articles = set()

def translate_text(text):
    """–ü–æ–∫—Ä–∞—â–µ–Ω–∏–π –ø–µ—Ä–µ–∫–ª–∞–¥"""
    try:
        # –°–ø–æ—á–∞—Ç–∫—É —á–∏—Å—Ç–∏–º–æ —Ç–µ–∫—Å—Ç
        text = re.sub(r'<[^>]+>', '', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        if len(text) > 500:
            text = text[:500]
            
        url = "https://api.mymemory.translated.net/get"
        params = {'q': text, 'langpair': 'en|uk'}
        response = requests.get(url, params=params, timeout=10)
        data = response.json()
        
        if 'responseData' in data:
            translated = data['responseData']['translatedText']
            if "MYMEMORY WARNING" not in translated.upper():
                return translated
        return text
    except:
        return text

def get_club_name(text):
    """–û—Ç—Ä–∏–º—É—î–º–æ —É–∫—Ä–∞—ó–Ω—Å—å–∫–µ —ñ–º'—è –∫–ª—É–±—É"""
    text_lower = text.lower()
    for eng_name, ua_name in CLUBS.items():
        if eng_name in text_lower:
            return ua_name
    return None

def get_league_name(text):
    """–û—Ç—Ä–∏–º—É—î–º–æ —É–∫—Ä–∞—ó–Ω—Å—å–∫–µ —ñ–º'—è –ª—ñ–≥–∏"""
    text_lower = text.lower()
    for eng_name, ua_name in LEAGUES.items():
        if eng_name in text_lower:
            return ua_name
    return None

def determine_post_type(title, description):
    """–í–∏–∑–Ω–∞—á–∞—î–º–æ —Ç–∏–ø –Ω–æ–≤–∏–Ω–∏ –¥–ª—è –µ–º–æ–¥–∑—ñ"""
    text = (title + " " + description).lower()
    
    if any(word in text for word in ["transfer", "signing", "deal", "million", "contract"]):
        return "transfer"
    elif any(word in text for word in ["injury", "ruled out", "injured", "fitness"]):
        return "injury"
    elif any(word in text for word in ["sacked", "fired", "appointed", "manager"]):
        return "manager"
    elif any(word in text for word in ["goal", "scored", "assist", "performance"]):
        return "performance"
    elif any(word in text for word in ["champions league", "europa league", "final"]):
        return "european"
    else:
        return "general"

def format_post(title, description, source="Football News", url=""):
    """–ü–æ–∫—Ä–∞—â–µ–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç –ø–æ—Å—Ç–∞"""
    
    # –í–∏–∑–Ω–∞—á–∞—î–º–æ —Ç–∏–ø –Ω–æ–≤–∏–Ω–∏
    post_type = determine_post_type(title, description)
    
    # –ï–º–æ–¥–∑—ñ –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Ç–∏–ø—É
    emoji_map = {
        "transfer": "üí∞",
        "injury": "üè•", 
        "manager": "üëî",
        "performance": "‚öΩ",
        "european": "üèÜ",
        "general": "üì∞"
    }
    
    main_emoji = emoji_map.get(post_type, "üì∞")
    
    # –ü–µ—Ä–µ–∫–ª–∞–¥–∞—î–º–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫
    title_ua = translate_text(title)
    
    # –®—É–∫–∞—î–º–æ –∫–ª—É–±–∏ —Ç–∞ –ª—ñ–≥–∏ –≤ —Ç–µ–∫—Å—Ç—ñ
    club = get_club_name(title + " " + description)
    league = get_league_name(title + " " + description)
    
    # –§–æ—Ä–º—É—î–º–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫
    header_parts = [main_emoji]
    if club:
        header_parts.append(club)
    if league:
        header_parts.append(league)
    
    header = " ".join(header_parts)
    
    # –ü–æ—á–∞—Ç–æ–∫ –ø–æ—Å—Ç–∞
    post = f"{header}\n\n"
    post += f"<b>{title_ua}</b>\n\n"
    
    # –û–ø–∏—Å –Ω–æ–≤–∏–Ω–∏
    if description:
        # –ß–∏—Å—Ç–∏–º–æ –æ–ø–∏—Å
        description = re.sub('<.*?>', '', description)
        description = re.sub(r'\s+', ' ', description).strip()
        
        # –û–±—Ä—ñ–∑–∞—î–º–æ —è–∫—â–æ –¥–æ–≤–≥–∏–π
        if len(description) > 400:
            description = description[:400] + "..."
            
        description_ua = translate_text(description)
        
        # –†–æ–∑–±–∏–≤–∞—î–º–æ –Ω–∞ –∞–±–∑–∞—Ü–∏ –¥–ª—è —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—ñ
        sentences = description_ua.split('. ')
        if len(sentences) > 1:
            first_part = '. '.join(sentences[:2]) + '.'
            post += f"{first_part}\n\n"
            
            if len(sentences) > 2:
                remaining = '. '.join(sentences[2:])
                post += f"<i>{remaining}</i>\n\n"
        else:
            post += f"{description_ua}\n\n"
    
    # –î–æ–¥–∞—î–º–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Ç–∏–ø—É –Ω–æ–≤–∏–Ω–∏
    context_map = {
        "transfer": "üíº <i>–¢—Ä–∞–Ω—Å—Ñ–µ—Ä–Ω—ñ –Ω–æ–≤–∏–Ω–∏</i>",
        "injury": "‚öïÔ∏è <i>–ú–µ–¥–∏—á–Ω—ñ –Ω–æ–≤–∏–Ω–∏</i>",
        "manager": "üè¢ <i>–ö–∞–¥—Ä–æ–≤—ñ –∑–º—ñ–Ω–∏</i>", 
        "performance": "üìä <i>–°–ø–æ—Ä—Ç–∏–≤–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏</i>",
        "european": "üåç <i>–Ñ–≤—Ä–æ–∫—É–±–∫–∏</i>",
        "general": "‚öΩ <i>–§—É—Ç–±–æ–ª—å–Ω—ñ –Ω–æ–≤–∏–Ω–∏</i>"
    }
    
    post += f"{context_map.get(post_type, '‚öΩ <i>–§—É—Ç–±–æ–ª—å–Ω—ñ –Ω–æ–≤–∏–Ω–∏</i>')}\n"
    post += f"üì∞ <i>–î–∂–µ—Ä–µ–ª–æ: {source}</i>"
    
    return post

def get_google_news():
    """–û—Ç—Ä–∏–º—É—î–º–æ –Ω–æ–≤–∏–Ω–∏ –∑ Google News RSS"""
    try:
        feed_url = 'https://news.google.com/rss/search?q=football+premier+league+transfer+injury+manager&hl=en&gl=GB&ceid=GB:en'
        feed = feedparser.parse(feed_url)
        
        articles = []
        for entry in feed.entries[:5]:  # –ë–µ—Äemo —Ç–æ–ø-5
            title = entry.title
            description = entry.get('summary', '')
            source = entry.get('source', {}).get('title', 'Google News')
            
            if is_important_news(title, description):
                articles.append({
                    'title': title,
                    'description': description,
                    'source': source,
                    'url': entry.link
                })
        
        return articles
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ Google News: {e}")
        return []

def scrape_sky_sports():
    """–ü–∞—Ä—Å–∏–º–æ Sky Sports"""
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        response = requests.get('https://www.skysports.com/football/news', headers=headers, timeout=10)
        soup = BeautifulSoup(response.content, 'html.parser')
        
        articles = []
        news_items = soup.find_all('div', class_='news-list__item')[:3]
        
        for item in news_items:
            title_elem = item.find('a', class_='news-list__headline-link')
            if title_elem:
                title = title_elem.text.strip()
                description_elem = item.find('p', class_='news-list__summary')
                description = description_elem.text.strip() if description_elem else ""
                
                if is_important_news(title, description):
                    articles.append({
                        'title': title,
                        'description': description,
                        'source': 'Sky Sports',
                        'url': 'https://www.skysports.com' + title_elem.get('href', '')
                    })
        
        return articles
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ Sky Sports: {e}")
        return []

def is_important_news(title, description):
    """–ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –≤–∞–∂–ª–∏–≤—ñ—Å—Ç—å –Ω–æ–≤–∏–Ω–∏"""
    text = (title + " " + description).lower()
    return any(keyword in text for keyword in IMPORTANT_KEYWORDS)

def get_football_news():
    """–ó–±–∏—Ä–∞—î–º–æ –Ω–æ–≤–∏–Ω–∏ –∑ —É—Å—ñ—Ö –¥–∂–µ—Ä–µ–ª"""
    all_articles = []
    
    print("üîç –ó–±–∏—Ä–∞—î–º–æ –Ω–æ–≤–∏–Ω–∏ –∑ Google News...")
    all_articles.extend(get_google_news())
    
    print("üîç –ü–∞—Ä—Å–∏–º–æ Sky Sports...")
    all_articles.extend(scrape_sky_sports())
    
    # –Ø–∫—â–æ —Ä–µ–∞–ª—å–Ω–∏—Ö –Ω–æ–≤–∏–Ω –Ω–µ–º–∞—î, –¥–æ–¥–∞—î–º–æ —Ç–µ—Å—Ç–æ–≤—ñ
    if not all_articles:
        print("üìù –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Ç–µ—Å—Ç–æ–≤—ñ –Ω–æ–≤–∏–Ω–∏...")
        test_news = [
            {
                "title": "Manchester United close to signing ‚Ç¨80m midfielder from Real Madrid",
                "description": "Manchester United are reportedly close to finalizing a deal for Real Madrid's talented midfielder in a transfer worth ‚Ç¨80 million. The Spanish international has been a long-term target for the Red Devils.",
                "source": "Sky Sports",
                "url": ""
            },
            {
                "title": "Liverpool's Mohamed Salah suffers injury setback, ruled out for three weeks", 
                "description": "Liverpool forward Mohamed Salah has suffered a hamstring injury during training and will be sidelined for approximately three weeks. The Egyptian international was in excellent form this season.",
                "source": "BBC Sport",
                "url": ""
            }
        ]
        all_articles = test_news
    
    # –§–æ—Ä–º–∞—Ç—É—î–º–æ –ø–æ—Å—Ç–∏
    formatted_posts = []
    for article in all_articles:
        if article['title'] not in processed_articles:
            formatted = format_post(
                article['title'], 
                article['description'], 
                article['source'],
                article.get('url', '')
            )
            formatted_posts.append(formatted)
            processed_articles.add(article['title'])
            
            print(f"‚úÖ –°—Ñ–æ—Ä–º–æ–≤–∞–Ω–æ –ø–æ—Å—Ç:")
            print("="*60)
            print(formatted)
            print("="*60)
    
    return formatted_posts

def send_message(text):
    """–ù–∞–¥—Å–∏–ª–∞—î–º–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤ Telegram"""
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    data = {
        "chat_id": CHANNEL_ID, 
        "text": text, 
        "parse_mode": "HTML",
        "disable_web_page_preview": True
    }
    return requests.post(url, data=data)

def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –±–æ—Ç–∞"""
    send_message("ü§ñ <b>Five Leagues Bot v2.0 –∑–∞–ø—É—â–µ–Ω–æ!</b> üá∫üá¶\n\n‚öΩ –ú–æ–Ω—ñ—Ç–æ—Ä–∏–º–æ —Ç–æ–ø-–Ω–æ–≤–∏–Ω–∏ —Ñ—É—Ç–±–æ–ª—É...")
    
    while True:
        try:
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"üïê {current_time} - –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–æ–≤–∏–Ω...")
            
            articles = get_football_news()
            
            if articles:
                # –ë–µ—Äemo –Ω–∞–π–∫—Ä–∞—â—É –Ω–æ–≤–∏–Ω—É
                best_article = articles[0]
                
                # –ù–∞–¥—Å–∏–ª–∞—î–º–æ –Ω–∞ –ø–æ–≥–æ–¥–∂–µ–Ω–Ω—è
                approval_msg = f"üìã <b>–ù–û–í–ò–ù–ê –ù–ê –ü–û–ì–û–î–ñ–ï–ù–ù–Ø:</b>\n\n{'-'*30}\n\n{best_article}\n\n{'-'*30}\n\n‚ùì <b>–ü—É–±–ª—ñ–∫—É–≤–∞—Ç–∏?</b> –¢–ê–ö/–ù–Ü"
                send_message(approval_msg)
                print("üì§ –ù–∞–¥—ñ—Å–ª–∞–Ω–æ –Ω–∞ –ø–æ–≥–æ–¥–∂–µ–Ω–Ω—è")
                
                # –Ø–∫—â–æ —î —â–µ –Ω–æ–≤–∏–Ω–∏, –∑–±–µ—Ä—ñ–≥–∞—î–º–æ —ó—Ö
                if len(articles) > 1:
                    print(f"üìù –ó–±–µ—Ä–µ–∂–µ–Ω–æ {len(articles)-1} –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –Ω–æ–≤–∏–Ω")
            else:
                print("‚ÑπÔ∏è –ù–æ–≤–∏—Ö –≤–∞–∂–ª–∏–≤–∏—Ö –Ω–æ–≤–∏–Ω –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
            
            # –ß–µ–∫–∞—î–º–æ 30 —Ö–≤–∏–ª–∏–Ω
            print("‚è∞ –ù–∞—Å—Ç—É–ø–Ω–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ —á–µ—Ä–µ–∑ 30 —Ö–≤–∏–ª–∏–Ω...")
            time.sleep(1800)
            
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
            time.sleep(300)  # –ß–µ–∫–∞—î–º–æ 5 —Ö–≤–∏–ª–∏–Ω –ø—Ä–∏ –ø–æ–º–∏–ª—Ü—ñ

if __name__ == "__main__":
    main()

# Render server –¥–ª—è —Ö–æ—Å—Ç–∏–Ω–≥—É
import threading
from http.server import HTTPServer, SimpleHTTPRequestHandler

def run_server():
    port = int(os.environ.get("PORT", 5000))
    server = HTTPServer(('', port), SimpleHTTPRequestHandler)
    print(f"üåê –°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω–æ –Ω–∞ –ø–æ—Ä—Ç—É {port}")
    server.serve_forever()

# –ó–∞–ø—É—Å–∫–∞—î–º–æ —Å–µ—Ä–≤–µ—Ä –≤ –æ–∫—Ä–µ–º–æ–º—É –ø–æ—Ç–æ—Ü—ñ
threading.Thread(target=run_server, daemon=True).start()
